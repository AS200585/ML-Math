# Matrices

"""
Matrices are two-dimensional arrays of numbers, symbols, or expressions, arranged in rows and columns.
They are a fundamental concept in linear algebra and are used to represent and solve systems of linear equations.
In machine learning, matrices are used to represent datasets, where each row corresponds to a data point and each column corresponds to a feature.

Operations on matrices, such as addition, subtraction, and multiplication, are essential for various algorithms, 
including linear regression, neural networks, and more.

Diagonal matrices are a special type of matrix where the entries outside the main diagonal are all zero. Only diagonal elements are non-zero.
Ones matrices are matrices where all the elements are equal to one.
Zeros matrices are matrices where all the elements are equal to zero.

Diagonal of a matrix refers to the entries that extend from the top left corner to the bottom right corner.
All numbers outside the diagonal are considered off-diagonal elements.

Symmetric matrices are square matrices that are equal to their transpose.
In other words, a matrix A is symmetric if A = A^T. In this matrix, 
the element at row i and column j is equal to the element at row j and column i.
2 or more symmetric matrices can be added or subtracted to produce another symmetric matrix.
Also, all the elements above the main diagonal are equal to their corresponding elements below the diagonal.

Identity matrices are square matrices with ones on the main diagonal and zeros elsewhere. It is denoted as I_n, where n is the size of the matrix.
"""